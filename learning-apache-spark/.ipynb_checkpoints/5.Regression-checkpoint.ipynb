{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link](https://runawayhorse001.github.io/LearningApacheSpark/regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set up spark context and SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:53:38.584759Z",
     "start_time": "2022-10-14T19:53:38.565473Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark import SparkContext , SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sparkContext = sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:53:49.275999Z",
     "start_time": "2022-10-14T19:53:46.322660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').\\\n",
    "                       options(header='true', \\\n",
    "                       inferschema='true').\\\n",
    "            load(\"./data/Advertising.csv\",header=True);\n",
    "df.show(5,True)\n",
    "df.printSchema()\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Convert the data to dense vector (features and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:53:51.513363Z",
     "start_time": "2022-10-14T19:53:51.204410Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# I provide two ways to build the features and labels\n",
    "\n",
    "# method 1 (good for small feature):\n",
    "#def transData(row):\n",
    "#    return Row(label=row[\"Sales\"],\n",
    "#               features=Vectors.dense([row[\"TV\"],\n",
    "#                                       row[\"Radio\"],\n",
    "#                                       row[\"Newspaper\"]]))\n",
    "\n",
    "# Method 2 (good for large features):\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Transform the dataset to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:53:55.289152Z",
     "start_time": "2022-10-14T19:53:52.495183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[230.1,37.8,69.2]| 22.1|\n",
      "| [44.5,39.3,45.1]| 10.4|\n",
      "| [17.2,45.9,69.3]|  9.3|\n",
      "|[151.5,41.3,58.5]| 18.5|\n",
      "|[180.8,10.8,58.4]| 12.9|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed= transData(df)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Deal With Categorical Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:53:56.151708Z",
     "start_time": "2022-10-14T19:53:55.290470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+-----------------+\n",
      "|         features|label|  indexedFeatures|\n",
      "+-----------------+-----+-----------------+\n",
      "|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|\n",
      "| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|\n",
      "| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|\n",
      "|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|\n",
      "|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|\n",
      "+-----------------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)\n",
    "data.show(5,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split the data into training and test sets (40% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:53:58.716505Z",
     "start_time": "2022-10-14T19:53:58.295172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|        features|label|\n",
      "+----------------+-----+\n",
      "|  [0.7,39.6,8.7]|  1.6|\n",
      "|  [4.1,11.6,5.7]|  3.2|\n",
      "| [7.3,28.1,41.4]|  5.5|\n",
      "|   [8.6,2.1,1.0]|  4.8|\n",
      "|[11.7,36.9,45.2]|  7.3|\n",
      "+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------+-----+\n",
      "|       features|label|\n",
      "+---------------+-----+\n",
      "| [5.4,29.9,9.4]|  5.3|\n",
      "|[7.8,38.9,50.6]|  6.6|\n",
      "| [8.4,27.2,2.1]|  5.7|\n",
      "|[8.7,48.9,75.0]|  7.2|\n",
      "|[13.1,0.4,25.6]|  5.3|\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = transformed.randomSplit([0.6, 0.4])\n",
    "trainingData.show(5)\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:01.737043Z",
     "start_time": "2022-10-14T19:54:01.325175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/14 14:54:01 WARN Instrumentation: [441de1d4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/10/14 14:54:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/14 14:54:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/10/14 14:54:01 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/10/14 14:54:01 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "# Define LinearRegression algorithm\n",
    "lr = LinearRegression()\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, lr])\n",
    "model = pipeline.fit(trainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Summary of the Model\n",
    "Spark has a poor summary function for data and model. I wrote a summary function which has similar format as R output for the linear regression in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:14.202156Z",
     "start_time": "2022-10-14T19:54:14.115815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: the last rows are the information for Intercept\n",
      "## -------------------------------------------------\n",
      "##   Estimate   |   Std.Error | t Values  |  P-value\n",
      "##   0.045336   0.001873   24.205   0.000000\n",
      "##   0.193150   0.010676   18.092   0.000000\n",
      "##   0.002284   0.007470    0.306   0.760343\n",
      "##   2.846897   0.395254    7.203   0.000000\n",
      "## ---\n",
      "## Mean squared error:  2.679128 , RMSE:  1.636804\n",
      "## Multiple R-squared: 0.894188 ,             Total iterations: 0\n"
     ]
    }
   ],
   "source": [
    "def modelsummary(model):\n",
    "    import numpy as np\n",
    "    print (\"Note: the last rows are the information for Intercept\")\n",
    "    print (\"##\",\"-------------------------------------------------\")\n",
    "    print (\"##\",\"  Estimate   |   Std.Error | t Values  |  P-value\")\n",
    "    coef = np.append(list(model.coefficients),model.intercept)\n",
    "    Summary=model.summary\n",
    "\n",
    "    for i in range(len(Summary.pValues)):\n",
    "        print (\"##\",'{:10.6f}'.format(coef[i]),\\\n",
    "        '{:10.6f}'.format(Summary.coefficientStandardErrors[i]),\\\n",
    "        '{:8.3f}'.format(Summary.tValues[i]),\\\n",
    "        '{:10.6f}'.format(Summary.pValues[i]))\n",
    "\n",
    "    print (\"##\",'---')\n",
    "    print (\"##\",\"Mean squared error: % .6f\" \\\n",
    "           % Summary.meanSquaredError, \", RMSE: % .6f\" \\\n",
    "           % Summary.rootMeanSquaredError )\n",
    "    print (\"##\",\"Multiple R-squared: %f\" % Summary.r2, \", \\\n",
    "            Total iterations: %i\"% Summary.totalIterations)\n",
    "modelsummary(model.stages[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:20.303798Z",
     "start_time": "2022-10-14T19:54:20.232435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, indexedFeatures: vector, prediction: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:22.128602Z",
     "start_time": "2022-10-14T19:54:22.039957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------------+\n",
      "|        features|label| indexedFeatures|\n",
      "+----------------+-----+----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|\n",
      "| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|\n",
      "|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n",
      "| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|\n",
      "| [13.1,0.4,25.6]|  5.3| [13.1,0.4,25.6]|\n",
      "|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|\n",
      "|[16.9,43.7,89.4]|  8.7|[16.9,43.7,89.4]|\n",
      "|[23.8,35.1,65.9]|  9.2|[23.8,35.1,65.9]|\n",
      "|[25.0,11.0,29.7]|  7.2|[25.0,11.0,29.7]|\n",
      "| [25.6,39.0,9.3]|  9.5| [25.6,39.0,9.3]|\n",
      "| [27.5,1.6,20.7]|  6.9| [27.5,1.6,20.7]|\n",
      "|[38.0,40.3,11.9]| 10.9|[38.0,40.3,11.9]|\n",
      "| [38.2,3.7,13.8]|  7.6| [38.2,3.7,13.8]|\n",
      "|[43.1,26.7,35.1]| 10.1|[43.1,26.7,35.1]|\n",
      "|[44.5,39.3,45.1]| 10.4|[44.5,39.3,45.1]|\n",
      "|[44.7,25.8,20.6]| 10.1|[44.7,25.8,20.6]|\n",
      "|[50.0,11.6,18.4]|  8.4|[50.0,11.6,18.4]|\n",
      "| [53.5,2.0,21.4]|  8.1| [53.5,2.0,21.4]|\n",
      "|[57.5,32.8,23.5]| 11.8|[57.5,32.8,23.5]|\n",
      "|[68.4,44.5,35.6]| 13.6|[68.4,44.5,35.6]|\n",
      "+----------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\",\"label\",\"indexedFeatures\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:27.833659Z",
     "start_time": "2022-10-14T19:54:27.741193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.73338\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:29.487382Z",
     "start_time": "2022-10-14T19:54:28.704009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 score: 0.8997768705853216\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r^2 score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5.2 Generalized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link](https://runawayhorse001.github.io/LearningApacheSpark/regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GeneralizedLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:54:47.633880Z",
     "start_time": "2022-10-14T19:54:47.447613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",\\\n",
    "                                  maxIter=10, regParam=0.3)\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, glr])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Summary of the Model\n",
    "Spark has a poor summary function for data and model. I wrote a summary function which has similar format as R output for the linear regression in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:55:20.029890Z",
     "start_time": "2022-10-14T19:55:19.553883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: the last rows are the information for Intercept\n",
      "## -------------------------------------------------\n",
      "##   Estimate   |   Std.Error | t Values  |  P-value\n",
      "##   0.042842   0.001842   23.260   0.000000\n",
      "##   0.181492   0.010423   17.413   0.000000\n",
      "##   0.005500   0.007292    0.754   0.452130\n",
      "##   3.379777   0.392207    8.617   0.000000\n",
      "## ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GeneralizedLinearRegressionTrainingSummary' object has no attribute 'meanSquaredError'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean squared error: \u001b[39m\u001b[38;5;132;01m% .6f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     17\u001b[0m            \u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mmeanSquaredError, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, RMSE: \u001b[39m\u001b[38;5;132;01m% .6f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     18\u001b[0m            \u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mrootMeanSquaredError )\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple R-squared: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mr2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m            Total iterations: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mtotalIterations)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodelsummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 17\u001b[0m, in \u001b[0;36mmodelsummary\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:10.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(coef[i]),\\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:10.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Summary\u001b[38;5;241m.\u001b[39mcoefficientStandardErrors[i]),\\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:8.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Summary\u001b[38;5;241m.\u001b[39mtValues[i]),\\\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:10.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Summary\u001b[38;5;241m.\u001b[39mpValues[i]))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean squared error: \u001b[39m\u001b[38;5;132;01m% .6f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m---> 17\u001b[0m        \u001b[38;5;241m%\u001b[39m \u001b[43mSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeanSquaredError\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, RMSE: \u001b[39m\u001b[38;5;132;01m% .6f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     18\u001b[0m        \u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mrootMeanSquaredError )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple R-squared: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mr2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m        Total iterations: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m Summary\u001b[38;5;241m.\u001b[39mtotalIterations)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneralizedLinearRegressionTrainingSummary' object has no attribute 'meanSquaredError'"
     ]
    }
   ],
   "source": [
    "def modelsummary(model):\n",
    "    import numpy as np\n",
    "    print (\"Note: the last rows are the information for Intercept\")\n",
    "    print (\"##\",\"-------------------------------------------------\")\n",
    "    print (\"##\",\"  Estimate   |   Std.Error | t Values  |  P-value\")\n",
    "    coef = np.append(list(model.coefficients),model.intercept)\n",
    "    Summary=model.summary\n",
    "\n",
    "    for i in range(len(Summary.pValues)):\n",
    "        print (\"##\",'{:10.6f}'.format(coef[i]),\\\n",
    "        '{:10.6f}'.format(Summary.coefficientStandardErrors[i]),\\\n",
    "        '{:8.3f}'.format(Summary.tValues[i]),\\\n",
    "        '{:10.6f}'.format(Summary.pValues[i]))\n",
    "\n",
    "    print (\"##\",'---')\n",
    "    print (\"##\",\"Mean squared error: % .6f\" \\\n",
    "           % Summary.meanSquaredError, \", RMSE: % .6f\" \\\n",
    "           % Summary.rootMeanSquaredError )\n",
    "    print (\"##\",\"Multiple R-squared: %f\" % Summary.r2, \", \\\n",
    "            Total iterations: %i\"% Summary.totalIterations)\n",
    "modelsummary(model.stages[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:55:44.864343Z",
     "start_time": "2022-10-14T19:55:44.822576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, indexedFeatures: vector, prediction: double]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:55:45.519666Z",
     "start_time": "2022-10-14T19:55:45.460026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------------+\n",
      "|        features|label| indexedFeatures|\n",
      "+----------------+-----+----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|\n",
      "| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|\n",
      "|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n",
      "| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|\n",
      "| [13.1,0.4,25.6]|  5.3| [13.1,0.4,25.6]|\n",
      "|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|\n",
      "|[16.9,43.7,89.4]|  8.7|[16.9,43.7,89.4]|\n",
      "|[23.8,35.1,65.9]|  9.2|[23.8,35.1,65.9]|\n",
      "|[25.0,11.0,29.7]|  7.2|[25.0,11.0,29.7]|\n",
      "| [25.6,39.0,9.3]|  9.5| [25.6,39.0,9.3]|\n",
      "| [27.5,1.6,20.7]|  6.9| [27.5,1.6,20.7]|\n",
      "|[38.0,40.3,11.9]| 10.9|[38.0,40.3,11.9]|\n",
      "| [38.2,3.7,13.8]|  7.6| [38.2,3.7,13.8]|\n",
      "|[43.1,26.7,35.1]| 10.1|[43.1,26.7,35.1]|\n",
      "|[44.5,39.3,45.1]| 10.4|[44.5,39.3,45.1]|\n",
      "|[44.7,25.8,20.6]| 10.1|[44.7,25.8,20.6]|\n",
      "|[50.0,11.6,18.4]|  8.4|[50.0,11.6,18.4]|\n",
      "| [53.5,2.0,21.4]|  8.1| [53.5,2.0,21.4]|\n",
      "|[57.5,32.8,23.5]| 11.8|[57.5,32.8,23.5]|\n",
      "|[68.4,44.5,35.6]| 13.6|[68.4,44.5,35.6]|\n",
      "+----------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\",\"label\",\"indexedFeatures\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:55:49.636175Z",
     "start_time": "2022-10-14T19:55:49.554924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.75231\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:55:50.617450Z",
     "start_time": "2022-10-14T19:55:50.512033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.897576528173309\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link](https://runawayhorse001.github.io/LearningApacheSpark/regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:56:28.988404Z",
     "start_time": "2022-10-14T19:56:28.356465Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:56:30.063700Z",
     "start_time": "2022-10-14T19:56:30.017371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, indexedFeatures: vector, prediction: double]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:56:30.862394Z",
     "start_time": "2022-10-14T19:56:30.797216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------------+\n",
      "|        features|label| indexedFeatures|\n",
      "+----------------+-----+----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|\n",
      "| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|\n",
      "|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n",
      "| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|\n",
      "| [13.1,0.4,25.6]|  5.3| [13.1,0.4,25.6]|\n",
      "|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|\n",
      "|[16.9,43.7,89.4]|  8.7|[16.9,43.7,89.4]|\n",
      "|[23.8,35.1,65.9]|  9.2|[23.8,35.1,65.9]|\n",
      "|[25.0,11.0,29.7]|  7.2|[25.0,11.0,29.7]|\n",
      "| [25.6,39.0,9.3]|  9.5| [25.6,39.0,9.3]|\n",
      "| [27.5,1.6,20.7]|  6.9| [27.5,1.6,20.7]|\n",
      "|[38.0,40.3,11.9]| 10.9|[38.0,40.3,11.9]|\n",
      "| [38.2,3.7,13.8]|  7.6| [38.2,3.7,13.8]|\n",
      "|[43.1,26.7,35.1]| 10.1|[43.1,26.7,35.1]|\n",
      "|[44.5,39.3,45.1]| 10.4|[44.5,39.3,45.1]|\n",
      "|[44.7,25.8,20.6]| 10.1|[44.7,25.8,20.6]|\n",
      "|[50.0,11.6,18.4]|  8.4|[50.0,11.6,18.4]|\n",
      "| [53.5,2.0,21.4]|  8.1| [53.5,2.0,21.4]|\n",
      "|[57.5,32.8,23.5]| 11.8|[57.5,32.8,23.5]|\n",
      "|[68.4,44.5,35.6]| 13.6|[68.4,44.5,35.6]|\n",
      "+----------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\",\"label\",\"indexedFeatures\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:56:32.309077Z",
     "start_time": "2022-10-14T19:56:32.226160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.62201\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:56:32.849199Z",
     "start_time": "2022-10-14T19:56:32.757262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9122424724118161\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link](https://runawayhorse001.github.io/LearningApacheSpark/regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:15.380838Z",
     "start_time": "2022-10-14T19:57:14.991210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "rf = RandomForestRegressor() # featuresCol=\"indexedFeatures\",numTrees=2, maxDepth=2, seed=42\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:16.813973Z",
     "start_time": "2022-10-14T19:57:16.742534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, indexedFeatures: vector, prediction: double]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:17.655528Z",
     "start_time": "2022-10-14T19:57:17.591803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------------+\n",
      "|        features|label| indexedFeatures|\n",
      "+----------------+-----+----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|\n",
      "| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|\n",
      "|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n",
      "| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|\n",
      "| [13.1,0.4,25.6]|  5.3| [13.1,0.4,25.6]|\n",
      "|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|\n",
      "|[16.9,43.7,89.4]|  8.7|[16.9,43.7,89.4]|\n",
      "|[23.8,35.1,65.9]|  9.2|[23.8,35.1,65.9]|\n",
      "|[25.0,11.0,29.7]|  7.2|[25.0,11.0,29.7]|\n",
      "| [25.6,39.0,9.3]|  9.5| [25.6,39.0,9.3]|\n",
      "| [27.5,1.6,20.7]|  6.9| [27.5,1.6,20.7]|\n",
      "|[38.0,40.3,11.9]| 10.9|[38.0,40.3,11.9]|\n",
      "| [38.2,3.7,13.8]|  7.6| [38.2,3.7,13.8]|\n",
      "|[43.1,26.7,35.1]| 10.1|[43.1,26.7,35.1]|\n",
      "|[44.5,39.3,45.1]| 10.4|[44.5,39.3,45.1]|\n",
      "|[44.7,25.8,20.6]| 10.1|[44.7,25.8,20.6]|\n",
      "|[50.0,11.6,18.4]|  8.4|[50.0,11.6,18.4]|\n",
      "| [53.5,2.0,21.4]|  8.1| [53.5,2.0,21.4]|\n",
      "|[57.5,32.8,23.5]| 11.8|[57.5,32.8,23.5]|\n",
      "|[68.4,44.5,35.6]| 13.6|[68.4,44.5,35.6]|\n",
      "+----------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\",\"label\",\"indexedFeatures\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:19.870700Z",
     "start_time": "2022-10-14T19:57:19.801373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2.38239\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:20.427265Z",
     "start_time": "2022-10-14T19:57:20.329530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.8106775745795071\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 GBT Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link](https://runawayhorse001.github.io/LearningApacheSpark/regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:57.529580Z",
     "start_time": "2022-10-14T19:57:54.783225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "rf = GBTRegressor() #numTrees=2, maxDepth=2, seed=42\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:57.573430Z",
     "start_time": "2022-10-14T19:57:57.530828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, indexedFeatures: vector, prediction: double]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:57.614793Z",
     "start_time": "2022-10-14T19:57:57.574378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------------+\n",
      "|        features|label| indexedFeatures|\n",
      "+----------------+-----+----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|\n",
      "| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|\n",
      "|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n",
      "| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|\n",
      "| [13.1,0.4,25.6]|  5.3| [13.1,0.4,25.6]|\n",
      "|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|\n",
      "|[16.9,43.7,89.4]|  8.7|[16.9,43.7,89.4]|\n",
      "|[23.8,35.1,65.9]|  9.2|[23.8,35.1,65.9]|\n",
      "|[25.0,11.0,29.7]|  7.2|[25.0,11.0,29.7]|\n",
      "| [25.6,39.0,9.3]|  9.5| [25.6,39.0,9.3]|\n",
      "| [27.5,1.6,20.7]|  6.9| [27.5,1.6,20.7]|\n",
      "|[38.0,40.3,11.9]| 10.9|[38.0,40.3,11.9]|\n",
      "| [38.2,3.7,13.8]|  7.6| [38.2,3.7,13.8]|\n",
      "|[43.1,26.7,35.1]| 10.1|[43.1,26.7,35.1]|\n",
      "|[44.5,39.3,45.1]| 10.4|[44.5,39.3,45.1]|\n",
      "|[44.7,25.8,20.6]| 10.1|[44.7,25.8,20.6]|\n",
      "|[50.0,11.6,18.4]|  8.4|[50.0,11.6,18.4]|\n",
      "| [53.5,2.0,21.4]|  8.1| [53.5,2.0,21.4]|\n",
      "|[57.5,32.8,23.5]| 11.8|[57.5,32.8,23.5]|\n",
      "|[68.4,44.5,35.6]| 13.6|[68.4,44.5,35.6]|\n",
      "+----------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\",\"label\",\"indexedFeatures\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:59.119949Z",
     "start_time": "2022-10-14T19:57:59.059470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.47746\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T19:57:59.498201Z",
     "start_time": "2022-10-14T19:57:59.404403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9271866710374933\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e16f15057b3d4aa43b2e9d0470701c81ab6d7c693cdc4ec27ee425bc62e7a7a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
